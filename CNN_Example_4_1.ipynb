{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "CNN_Example_4_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyTuqoTyE_Du",
        "colab_type": "text"
      },
      "source": [
        "[예제 4_1] \n",
        "2 conv / 1 flatten CNN 구조를 이용하여 index_label_prediction 값을 출력하는 코드를 구현하고. 필터 개수가 변화할 때 기존 코드의 어느 부분이 변경되는지 확인하시오 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wcEVJdRCeXO1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8628e206-5185-4ecd-c25b-ba7f54875120"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eprj1ComWHp7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "7272f0ea-96fa-4d3d-84cd-d958669e24e5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
        "\n",
        "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
        "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
        "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
        "\n",
        "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
        "\n",
        "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
        "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
        "\n",
        "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            " 55000 10000 5000\n",
            "\n",
            "train image shape =  (55000, 784)\n",
            "train label shape =  (55000, 10)\n",
            "test image shape =  (10000, 784)\n",
            "test label shape =  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XMI0w-KUeXO7",
        "colab": {}
      },
      "source": [
        "# Hyper-Parameter\n",
        "learning_rate = 0.001  # 학습율\n",
        "epochs = 50            # 반복횟수\n",
        "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KJX7CkOFeXPA",
        "colab": {}
      },
      "source": [
        "# 입력과 정답을 위한 플레이스홀더 정의\n",
        "X = tf.placeholder(tf.float32, [None, 784])  \n",
        "\n",
        "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28X28X1 (black/white)\n",
        "\n",
        "\n",
        "T = tf.placeholder(tf.float32, [None, 10])  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0aThyxBVeXPE",
        "colab": {}
      },
      "source": [
        "# 1번째 컨볼루션 층\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  \n",
        "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
        "\n",
        "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
        "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z2 = tf.nn.relu(C2+b2)\n",
        "\n",
        "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
        "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uUEChtlgeXPI",
        "colab": {}
      },
      "source": [
        "# 2번째 컨볼루션 층, 4X4X64 개 필터\n",
        "W3 = tf.Variable(tf.random_normal([4, 4, 32, 64], stddev=0.01))  \n",
        "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
        "\n",
        "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
        "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z3 = tf.nn.relu(C3+b3)\n",
        "\n",
        "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
        "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WB9boOK0eXPM",
        "colab": {}
      },
      "source": [
        "# 7X7 크기를 가진 64개의 activation map을 flatten 시킴\n",
        "A3_flat = P3_flat = tf.reshape(A3, [-1, 7*7*64])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvpTuu89eXPR",
        "colab": {}
      },
      "source": [
        "# 출력층\n",
        "W4 = tf.Variable(tf.random_normal([7*7*64, 10], stddev=0.01))\n",
        "b4 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "# 출력층 선형회귀  값 Z4, 즉 softmax 에 들어가는 입력 값\n",
        "Z4 = logits = tf.matmul(A3_flat, W4) + b4    # 선형회귀 값 Z4\n",
        "\n",
        "y = A4 = tf.nn.softmax(Z4)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WuEvwMjVeXPV",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z4, labels=T) )\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DwYNZP2qeXPY",
        "colab": {}
      },
      "source": [
        "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
        "predicted_val = tf.equal( tf.argmax(A4, 1), tf.argmax(T, 1) )\n",
        "\n",
        "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
        "\n",
        "# index list 출력\n",
        "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
        "\n",
        "# 예측값 처리\n",
        "predicted_list = tf.argmax(A4, 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "woyijCk2eXPc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7762ac93-9ba2-455b-ade6-e2a85c6bfe35"
      },
      "source": [
        "index_label_prediction_list = []\n",
        "\n",
        "with  tf.Session()  as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    for i in range(epochs):    \n",
        "        \n",
        "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
        "\n",
        "        for step in range(total_batch):\n",
        "            \n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
        "        \n",
        "            if step % 100 == 0:\n",
        "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
        "    \n",
        "    end_time = datetime.now() \n",
        "    \n",
        "    print(\"\\nelapsed time = \", end_time - start_time) \n",
        "    \n",
        "    # Accuracy 확인\n",
        "    test_x_data = mnist.test.images    # 10000 X 784\n",
        "    test_t_data = mnist.test.labels    # 10000 X 10\n",
        "    \n",
        "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
        "    \n",
        "    print(\"\\nAccuracy = \", accuracy_val)\n",
        "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
        "    print(\"index_label.shape = \", index_label.shape)\n",
        "    \n",
        "    index_label_list = list(index_label)\n",
        "    print(\"length of index_label_list = \", len(index_label_list))\n",
        "    print(\"false label count = \", index_label_list.count([0]))\n",
        "        \n",
        "    \n",
        "    temp_list = [] \n",
        "    \n",
        "    for index in range(len(index_label)):\n",
        "        \n",
        "        if index_label[index] == 0:\n",
        "            \n",
        "            temp_list.append(index)\n",
        "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
        "            temp_list.append(predicted_list_val[index])\n",
        "            \n",
        "            index_label_prediction_list.append(temp_list)\n",
        "            \n",
        "            temp_list = []\n",
        "            \n",
        "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs =  0 , step =  0 , loss_val =  2.6451402\n",
            "epochs =  0 , step =  100 , loss_val =  0.3865358\n",
            "epochs =  0 , step =  200 , loss_val =  0.28520158\n",
            "epochs =  0 , step =  300 , loss_val =  0.17970553\n",
            "epochs =  0 , step =  400 , loss_val =  0.13234611\n",
            "epochs =  0 , step =  500 , loss_val =  0.1771366\n",
            "epochs =  1 , step =  0 , loss_val =  0.17210054\n",
            "epochs =  1 , step =  100 , loss_val =  0.07373128\n",
            "epochs =  1 , step =  200 , loss_val =  0.082699426\n",
            "epochs =  1 , step =  300 , loss_val =  0.05851735\n",
            "epochs =  1 , step =  400 , loss_val =  0.04745235\n",
            "epochs =  1 , step =  500 , loss_val =  0.1429716\n",
            "epochs =  2 , step =  0 , loss_val =  0.082855046\n",
            "epochs =  2 , step =  100 , loss_val =  0.073159054\n",
            "epochs =  2 , step =  200 , loss_val =  0.024922756\n",
            "epochs =  2 , step =  300 , loss_val =  0.12185547\n",
            "epochs =  2 , step =  400 , loss_val =  0.057318944\n",
            "epochs =  2 , step =  500 , loss_val =  0.035220347\n",
            "epochs =  3 , step =  0 , loss_val =  0.033246752\n",
            "epochs =  3 , step =  100 , loss_val =  0.028363073\n",
            "epochs =  3 , step =  200 , loss_val =  0.023338513\n",
            "epochs =  3 , step =  300 , loss_val =  0.03384079\n",
            "epochs =  3 , step =  400 , loss_val =  0.04189527\n",
            "epochs =  3 , step =  500 , loss_val =  0.024878735\n",
            "epochs =  4 , step =  0 , loss_val =  0.21133393\n",
            "epochs =  4 , step =  100 , loss_val =  0.0066909874\n",
            "epochs =  4 , step =  200 , loss_val =  0.022029692\n",
            "epochs =  4 , step =  300 , loss_val =  0.09811341\n",
            "epochs =  4 , step =  400 , loss_val =  0.031741142\n",
            "epochs =  4 , step =  500 , loss_val =  0.037805945\n",
            "epochs =  5 , step =  0 , loss_val =  0.03304428\n",
            "epochs =  5 , step =  100 , loss_val =  0.0038782074\n",
            "epochs =  5 , step =  200 , loss_val =  0.033751193\n",
            "epochs =  5 , step =  300 , loss_val =  0.007845725\n",
            "epochs =  5 , step =  400 , loss_val =  0.018223094\n",
            "epochs =  5 , step =  500 , loss_val =  0.020350039\n",
            "epochs =  6 , step =  0 , loss_val =  0.004294148\n",
            "epochs =  6 , step =  100 , loss_val =  0.056054786\n",
            "epochs =  6 , step =  200 , loss_val =  0.048423506\n",
            "epochs =  6 , step =  300 , loss_val =  0.004515182\n",
            "epochs =  6 , step =  400 , loss_val =  0.09609116\n",
            "epochs =  6 , step =  500 , loss_val =  0.023376675\n",
            "epochs =  7 , step =  0 , loss_val =  0.05699069\n",
            "epochs =  7 , step =  100 , loss_val =  0.04451777\n",
            "epochs =  7 , step =  200 , loss_val =  0.041736685\n",
            "epochs =  7 , step =  300 , loss_val =  0.00905291\n",
            "epochs =  7 , step =  400 , loss_val =  0.010202779\n",
            "epochs =  7 , step =  500 , loss_val =  0.040253166\n",
            "epochs =  8 , step =  0 , loss_val =  0.038894266\n",
            "epochs =  8 , step =  100 , loss_val =  0.010384503\n",
            "epochs =  8 , step =  200 , loss_val =  0.0043499926\n",
            "epochs =  8 , step =  300 , loss_val =  0.055152565\n",
            "epochs =  8 , step =  400 , loss_val =  0.027841719\n",
            "epochs =  8 , step =  500 , loss_val =  0.008303195\n",
            "epochs =  9 , step =  0 , loss_val =  0.002887712\n",
            "epochs =  9 , step =  100 , loss_val =  0.01669766\n",
            "epochs =  9 , step =  200 , loss_val =  0.006825683\n",
            "epochs =  9 , step =  300 , loss_val =  0.0015841088\n",
            "epochs =  9 , step =  400 , loss_val =  0.030549856\n",
            "epochs =  9 , step =  500 , loss_val =  0.011779349\n",
            "epochs =  10 , step =  0 , loss_val =  0.008330303\n",
            "epochs =  10 , step =  100 , loss_val =  0.011259449\n",
            "epochs =  10 , step =  200 , loss_val =  0.025805783\n",
            "epochs =  10 , step =  300 , loss_val =  0.0036896905\n",
            "epochs =  10 , step =  400 , loss_val =  0.022325657\n",
            "epochs =  10 , step =  500 , loss_val =  0.0244166\n",
            "epochs =  11 , step =  0 , loss_val =  0.008363511\n",
            "epochs =  11 , step =  100 , loss_val =  0.0014404776\n",
            "epochs =  11 , step =  200 , loss_val =  0.0014436543\n",
            "epochs =  11 , step =  300 , loss_val =  0.0021833286\n",
            "epochs =  11 , step =  400 , loss_val =  0.027357167\n",
            "epochs =  11 , step =  500 , loss_val =  0.027047431\n",
            "epochs =  12 , step =  0 , loss_val =  0.0104972245\n",
            "epochs =  12 , step =  100 , loss_val =  0.0065835654\n",
            "epochs =  12 , step =  200 , loss_val =  0.06705386\n",
            "epochs =  12 , step =  300 , loss_val =  0.0043742624\n",
            "epochs =  12 , step =  400 , loss_val =  0.004168876\n",
            "epochs =  12 , step =  500 , loss_val =  0.038643554\n",
            "epochs =  13 , step =  0 , loss_val =  0.026096435\n",
            "epochs =  13 , step =  100 , loss_val =  0.0019809362\n",
            "epochs =  13 , step =  200 , loss_val =  0.0035500643\n",
            "epochs =  13 , step =  300 , loss_val =  0.0035526701\n",
            "epochs =  13 , step =  400 , loss_val =  0.09078136\n",
            "epochs =  13 , step =  500 , loss_val =  0.044483576\n",
            "epochs =  14 , step =  0 , loss_val =  0.007135397\n",
            "epochs =  14 , step =  100 , loss_val =  0.008427066\n",
            "epochs =  14 , step =  200 , loss_val =  0.01561015\n",
            "epochs =  14 , step =  300 , loss_val =  0.0013276356\n",
            "epochs =  14 , step =  400 , loss_val =  0.0019623938\n",
            "epochs =  14 , step =  500 , loss_val =  0.009549318\n",
            "epochs =  15 , step =  0 , loss_val =  0.0017563537\n",
            "epochs =  15 , step =  100 , loss_val =  0.0010136293\n",
            "epochs =  15 , step =  200 , loss_val =  0.0041486123\n",
            "epochs =  15 , step =  300 , loss_val =  0.002365982\n",
            "epochs =  15 , step =  400 , loss_val =  0.008544277\n",
            "epochs =  15 , step =  500 , loss_val =  0.004655379\n",
            "epochs =  16 , step =  0 , loss_val =  0.003839077\n",
            "epochs =  16 , step =  100 , loss_val =  0.0011374417\n",
            "epochs =  16 , step =  200 , loss_val =  0.0001239877\n",
            "epochs =  16 , step =  300 , loss_val =  0.0026959148\n",
            "epochs =  16 , step =  400 , loss_val =  0.0021716324\n",
            "epochs =  16 , step =  500 , loss_val =  0.0032154876\n",
            "epochs =  17 , step =  0 , loss_val =  0.0001934033\n",
            "epochs =  17 , step =  100 , loss_val =  0.010571902\n",
            "epochs =  17 , step =  200 , loss_val =  0.00013955549\n",
            "epochs =  17 , step =  300 , loss_val =  0.001926305\n",
            "epochs =  17 , step =  400 , loss_val =  0.011203937\n",
            "epochs =  17 , step =  500 , loss_val =  0.000599317\n",
            "epochs =  18 , step =  0 , loss_val =  0.0024472608\n",
            "epochs =  18 , step =  100 , loss_val =  0.00019832607\n",
            "epochs =  18 , step =  200 , loss_val =  0.0011360698\n",
            "epochs =  18 , step =  300 , loss_val =  0.06557137\n",
            "epochs =  18 , step =  400 , loss_val =  0.016708951\n",
            "epochs =  18 , step =  500 , loss_val =  0.00016485181\n",
            "epochs =  19 , step =  0 , loss_val =  0.0006134419\n",
            "epochs =  19 , step =  100 , loss_val =  0.00030253467\n",
            "epochs =  19 , step =  200 , loss_val =  0.0013224239\n",
            "epochs =  19 , step =  300 , loss_val =  0.003310176\n",
            "epochs =  19 , step =  400 , loss_val =  8.5232736e-05\n",
            "epochs =  19 , step =  500 , loss_val =  0.0032776145\n",
            "epochs =  20 , step =  0 , loss_val =  0.00031973142\n",
            "epochs =  20 , step =  100 , loss_val =  0.0009793901\n",
            "epochs =  20 , step =  200 , loss_val =  0.00083390815\n",
            "epochs =  20 , step =  300 , loss_val =  0.003616156\n",
            "epochs =  20 , step =  400 , loss_val =  0.007165745\n",
            "epochs =  20 , step =  500 , loss_val =  0.0027731701\n",
            "epochs =  21 , step =  0 , loss_val =  0.000396079\n",
            "epochs =  21 , step =  100 , loss_val =  0.0025295091\n",
            "epochs =  21 , step =  200 , loss_val =  3.774681e-05\n",
            "epochs =  21 , step =  300 , loss_val =  0.009640644\n",
            "epochs =  21 , step =  400 , loss_val =  0.015656522\n",
            "epochs =  21 , step =  500 , loss_val =  0.0017281526\n",
            "epochs =  22 , step =  0 , loss_val =  0.0043686866\n",
            "epochs =  22 , step =  100 , loss_val =  0.0034619612\n",
            "epochs =  22 , step =  200 , loss_val =  0.000907374\n",
            "epochs =  22 , step =  300 , loss_val =  0.0004631798\n",
            "epochs =  22 , step =  400 , loss_val =  0.0005287362\n",
            "epochs =  22 , step =  500 , loss_val =  0.08490266\n",
            "epochs =  23 , step =  0 , loss_val =  0.004789061\n",
            "epochs =  23 , step =  100 , loss_val =  0.0005884338\n",
            "epochs =  23 , step =  200 , loss_val =  0.00021748336\n",
            "epochs =  23 , step =  300 , loss_val =  0.00040980123\n",
            "epochs =  23 , step =  400 , loss_val =  0.0049127275\n",
            "epochs =  23 , step =  500 , loss_val =  3.7188725e-05\n",
            "epochs =  24 , step =  0 , loss_val =  0.00060975103\n",
            "epochs =  24 , step =  100 , loss_val =  0.0010482029\n",
            "epochs =  24 , step =  200 , loss_val =  2.9703928e-05\n",
            "epochs =  24 , step =  300 , loss_val =  0.0020404265\n",
            "epochs =  24 , step =  400 , loss_val =  0.00049634895\n",
            "epochs =  24 , step =  500 , loss_val =  0.00039930202\n",
            "epochs =  25 , step =  0 , loss_val =  0.00012270932\n",
            "epochs =  25 , step =  100 , loss_val =  0.00023005069\n",
            "epochs =  25 , step =  200 , loss_val =  6.596341e-05\n",
            "epochs =  25 , step =  300 , loss_val =  0.009803817\n",
            "epochs =  25 , step =  400 , loss_val =  0.0025859466\n",
            "epochs =  25 , step =  500 , loss_val =  0.00043111097\n",
            "epochs =  26 , step =  0 , loss_val =  8.172808e-05\n",
            "epochs =  26 , step =  100 , loss_val =  5.771408e-05\n",
            "epochs =  26 , step =  200 , loss_val =  0.001580707\n",
            "epochs =  26 , step =  300 , loss_val =  0.00017223686\n",
            "epochs =  26 , step =  400 , loss_val =  0.004495643\n",
            "epochs =  26 , step =  500 , loss_val =  0.017491948\n",
            "epochs =  27 , step =  0 , loss_val =  0.08985743\n",
            "epochs =  27 , step =  100 , loss_val =  0.00037960557\n",
            "epochs =  27 , step =  200 , loss_val =  0.000102763624\n",
            "epochs =  27 , step =  300 , loss_val =  0.0008931088\n",
            "epochs =  27 , step =  400 , loss_val =  0.00018489825\n",
            "epochs =  27 , step =  500 , loss_val =  0.0006760992\n",
            "epochs =  28 , step =  0 , loss_val =  0.0006498566\n",
            "epochs =  28 , step =  100 , loss_val =  0.0015489374\n",
            "epochs =  28 , step =  200 , loss_val =  0.00012346111\n",
            "epochs =  28 , step =  300 , loss_val =  7.216306e-05\n",
            "epochs =  28 , step =  400 , loss_val =  0.0010132567\n",
            "epochs =  28 , step =  500 , loss_val =  0.00011384457\n",
            "epochs =  29 , step =  0 , loss_val =  0.0009784272\n",
            "epochs =  29 , step =  100 , loss_val =  0.0065563624\n",
            "epochs =  29 , step =  200 , loss_val =  0.00010266555\n",
            "epochs =  29 , step =  300 , loss_val =  5.6166595e-05\n",
            "epochs =  29 , step =  400 , loss_val =  0.045442406\n",
            "epochs =  29 , step =  500 , loss_val =  0.0032670307\n",
            "epochs =  30 , step =  0 , loss_val =  0.00043724765\n",
            "epochs =  30 , step =  100 , loss_val =  0.07616789\n",
            "epochs =  30 , step =  200 , loss_val =  0.0008513131\n",
            "epochs =  30 , step =  300 , loss_val =  0.00015876537\n",
            "epochs =  30 , step =  400 , loss_val =  0.00010204382\n",
            "epochs =  30 , step =  500 , loss_val =  0.003673695\n",
            "epochs =  31 , step =  0 , loss_val =  0.00010494182\n",
            "epochs =  31 , step =  100 , loss_val =  0.00014458092\n",
            "epochs =  31 , step =  200 , loss_val =  0.008367229\n",
            "epochs =  31 , step =  300 , loss_val =  0.0019145884\n",
            "epochs =  31 , step =  400 , loss_val =  0.0009456266\n",
            "epochs =  31 , step =  500 , loss_val =  0.0009217955\n",
            "epochs =  32 , step =  0 , loss_val =  0.00010334231\n",
            "epochs =  32 , step =  100 , loss_val =  0.0003691789\n",
            "epochs =  32 , step =  200 , loss_val =  1.1925803e-05\n",
            "epochs =  32 , step =  300 , loss_val =  0.006982424\n",
            "epochs =  32 , step =  400 , loss_val =  1.4716767e-05\n",
            "epochs =  32 , step =  500 , loss_val =  0.0022523436\n",
            "epochs =  33 , step =  0 , loss_val =  9.051112e-05\n",
            "epochs =  33 , step =  100 , loss_val =  0.00053354737\n",
            "epochs =  33 , step =  200 , loss_val =  0.000121670266\n",
            "epochs =  33 , step =  300 , loss_val =  0.0006340934\n",
            "epochs =  33 , step =  400 , loss_val =  1.7654613e-06\n",
            "epochs =  33 , step =  500 , loss_val =  0.002665115\n",
            "epochs =  34 , step =  0 , loss_val =  0.00013437055\n",
            "epochs =  34 , step =  100 , loss_val =  1.1402179e-05\n",
            "epochs =  34 , step =  200 , loss_val =  0.0073586176\n",
            "epochs =  34 , step =  300 , loss_val =  0.00013521157\n",
            "epochs =  34 , step =  400 , loss_val =  0.00026800254\n",
            "epochs =  34 , step =  500 , loss_val =  0.0003354112\n",
            "epochs =  35 , step =  0 , loss_val =  0.0013648889\n",
            "epochs =  35 , step =  100 , loss_val =  0.0018477704\n",
            "epochs =  35 , step =  200 , loss_val =  0.0010043782\n",
            "epochs =  35 , step =  300 , loss_val =  0.007453444\n",
            "epochs =  35 , step =  400 , loss_val =  0.00020005701\n",
            "epochs =  35 , step =  500 , loss_val =  5.154365e-05\n",
            "epochs =  36 , step =  0 , loss_val =  0.001360668\n",
            "epochs =  36 , step =  100 , loss_val =  0.0011727128\n",
            "epochs =  36 , step =  200 , loss_val =  0.0009895813\n",
            "epochs =  36 , step =  300 , loss_val =  0.0010520479\n",
            "epochs =  36 , step =  400 , loss_val =  0.000759576\n",
            "epochs =  36 , step =  500 , loss_val =  6.704626e-05\n",
            "epochs =  37 , step =  0 , loss_val =  9.882967e-05\n",
            "epochs =  37 , step =  100 , loss_val =  3.7526104e-05\n",
            "epochs =  37 , step =  200 , loss_val =  1.9650292e-05\n",
            "epochs =  37 , step =  300 , loss_val =  0.0005533162\n",
            "epochs =  37 , step =  400 , loss_val =  4.6091485e-05\n",
            "epochs =  37 , step =  500 , loss_val =  4.0385366e-06\n",
            "epochs =  38 , step =  0 , loss_val =  0.000104377184\n",
            "epochs =  38 , step =  100 , loss_val =  3.576542e-05\n",
            "epochs =  38 , step =  200 , loss_val =  4.706259e-05\n",
            "epochs =  38 , step =  300 , loss_val =  0.0001606027\n",
            "epochs =  38 , step =  400 , loss_val =  4.795427e-05\n",
            "epochs =  38 , step =  500 , loss_val =  0.00013883939\n",
            "epochs =  39 , step =  0 , loss_val =  2.9582348e-05\n",
            "epochs =  39 , step =  100 , loss_val =  5.7088937e-06\n",
            "epochs =  39 , step =  200 , loss_val =  0.00011340117\n",
            "epochs =  39 , step =  300 , loss_val =  3.144924e-05\n",
            "epochs =  39 , step =  400 , loss_val =  0.00019408534\n",
            "epochs =  39 , step =  500 , loss_val =  1.1086004e-06\n",
            "epochs =  40 , step =  0 , loss_val =  0.00015177754\n",
            "epochs =  40 , step =  100 , loss_val =  2.2696709e-06\n",
            "epochs =  40 , step =  200 , loss_val =  0.00032368864\n",
            "epochs =  40 , step =  300 , loss_val =  2.734333e-06\n",
            "epochs =  40 , step =  400 , loss_val =  6.687575e-07\n",
            "epochs =  40 , step =  500 , loss_val =  2.5592212e-06\n",
            "epochs =  41 , step =  0 , loss_val =  1.3975244e-05\n",
            "epochs =  41 , step =  100 , loss_val =  8.529321e-06\n",
            "epochs =  41 , step =  200 , loss_val =  2.2172126e-06\n",
            "epochs =  41 , step =  300 , loss_val =  1.4073731e-05\n",
            "epochs =  41 , step =  400 , loss_val =  2.1336176e-05\n",
            "epochs =  41 , step =  500 , loss_val =  6.8393874e-06\n",
            "epochs =  42 , step =  0 , loss_val =  2.5950658e-06\n",
            "epochs =  42 , step =  100 , loss_val =  6.793823e-05\n",
            "epochs =  42 , step =  200 , loss_val =  4.3844033e-05\n",
            "epochs =  42 , step =  300 , loss_val =  1.6483562e-05\n",
            "epochs =  42 , step =  400 , loss_val =  1.2872511e-05\n",
            "epochs =  42 , step =  500 , loss_val =  7.128586e-07\n",
            "epochs =  43 , step =  0 , loss_val =  8.903414e-06\n",
            "epochs =  43 , step =  100 , loss_val =  2.3920327e-05\n",
            "epochs =  43 , step =  200 , loss_val =  4.363844e-06\n",
            "epochs =  43 , step =  300 , loss_val =  3.908119e-06\n",
            "epochs =  43 , step =  400 , loss_val =  8.763043e-06\n",
            "epochs =  43 , step =  500 , loss_val =  1.7140786e-05\n",
            "epochs =  44 , step =  0 , loss_val =  1.6043788e-05\n",
            "epochs =  44 , step =  100 , loss_val =  3.2081065e-05\n",
            "epochs =  44 , step =  200 , loss_val =  1.7071245e-05\n",
            "epochs =  44 , step =  300 , loss_val =  5.352438e-07\n",
            "epochs =  44 , step =  400 , loss_val =  3.4972616e-06\n",
            "epochs =  44 , step =  500 , loss_val =  5.1984157e-06\n",
            "epochs =  45 , step =  0 , loss_val =  3.8177427e-06\n",
            "epochs =  45 , step =  100 , loss_val =  3.8385053e-07\n",
            "epochs =  45 , step =  200 , loss_val =  2.8498987e-05\n",
            "epochs =  45 , step =  300 , loss_val =  6.95172e-06\n",
            "epochs =  45 , step =  400 , loss_val =  5.643022e-06\n",
            "epochs =  45 , step =  500 , loss_val =  1.147552e-05\n",
            "epochs =  46 , step =  0 , loss_val =  2.740288e-06\n",
            "epochs =  46 , step =  100 , loss_val =  0.00010779187\n",
            "epochs =  46 , step =  200 , loss_val =  3.7191528e-06\n",
            "epochs =  46 , step =  300 , loss_val =  5.5062924e-06\n",
            "epochs =  46 , step =  400 , loss_val =  3.6960055e-06\n",
            "epochs =  46 , step =  500 , loss_val =  1.2647662e-06\n",
            "epochs =  47 , step =  0 , loss_val =  5.2690046e-07\n",
            "epochs =  47 , step =  100 , loss_val =  2.5152872e-07\n",
            "epochs =  47 , step =  200 , loss_val =  9.2504735e-07\n",
            "epochs =  47 , step =  300 , loss_val =  6.341754e-07\n",
            "epochs =  47 , step =  400 , loss_val =  7.867796e-08\n",
            "epochs =  47 , step =  500 , loss_val =  1.2919969e-05\n",
            "epochs =  48 , step =  0 , loss_val =  1.5347066e-05\n",
            "epochs =  48 , step =  100 , loss_val =  5.2987543e-06\n",
            "epochs =  48 , step =  200 , loss_val =  1.19208615e-07\n",
            "epochs =  48 , step =  300 , loss_val =  2.4960877e-06\n",
            "epochs =  48 , step =  400 , loss_val =  1.1875942e-05\n",
            "epochs =  48 , step =  500 , loss_val =  5.3075353e-05\n",
            "epochs =  49 , step =  0 , loss_val =  2.3126502e-07\n",
            "epochs =  49 , step =  100 , loss_val =  3.039809e-07\n",
            "epochs =  49 , step =  200 , loss_val =  2.4185201e-06\n",
            "epochs =  49 , step =  300 , loss_val =  8.82979e-06\n",
            "epochs =  49 , step =  400 , loss_val =  4.6968154e-07\n",
            "epochs =  49 , step =  500 , loss_val =  7.8676464e-07\n",
            "\n",
            "elapsed time =  0:02:03.950186\n",
            "\n",
            "Accuracy =  0.9906\n",
            "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
            "index_label.shape =  (10000,)\n",
            "length of index_label_list =  10000\n",
            "false label count =  94\n",
            "\n",
            "length of index_label_false_list 94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ysJo9tWEeXPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0a5c8d28-5774-4abe-d615-9f069ecaa2ea"
      },
      "source": [
        "# index_label_prediction_list\n",
        "print(index_label_prediction_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18, 3, 5], [115, 4, 9], [259, 6, 0], [321, 2, 7], [340, 5, 3], [445, 6, 0], [619, 1, 8], [629, 2, 8], [659, 2, 1], [674, 5, 3], [684, 7, 2], [882, 9, 7], [883, 3, 5], [947, 8, 9], [1014, 6, 5], [1039, 7, 2], [1112, 4, 6], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1260, 7, 1], [1299, 5, 7], [1319, 8, 0], [1393, 5, 3], [1530, 8, 7], [1709, 9, 5], [1790, 2, 7], [1901, 9, 4], [2035, 5, 3], [2070, 7, 9], [2098, 2, 0], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2293, 9, 2], [2387, 9, 1], [2414, 9, 4], [2454, 6, 5], [2488, 2, 4], [2597, 5, 3], [2654, 6, 1], [2720, 9, 4], [2760, 9, 4], [2896, 8, 0], [2939, 9, 5], [2953, 3, 5], [2995, 6, 5], [3062, 8, 3], [3073, 1, 2], [3225, 7, 9], [3422, 6, 0], [3520, 6, 4], [3558, 5, 0], [3727, 8, 9], [3751, 7, 2], [3808, 7, 8], [3850, 9, 4], [3853, 6, 8], [3871, 8, 3], [4176, 2, 7], [4201, 1, 7], [4497, 8, 7], [4536, 6, 5], [4571, 6, 8], [4740, 3, 5], [4763, 5, 6], [4783, 4, 9], [4807, 8, 0], [4823, 9, 4], [5749, 8, 5], [5937, 5, 3], [5955, 3, 8], [5997, 5, 9], [6571, 9, 3], [6576, 7, 1], [6597, 0, 7], [6625, 8, 2], [6651, 0, 8], [6783, 1, 6], [8059, 2, 1], [8408, 8, 5], [9009, 7, 2], [9015, 7, 2], [9024, 7, 2], [9540, 1, 8], [9642, 9, 7], [9664, 2, 7], [9679, 6, 3], [9692, 9, 7], [9729, 5, 6], [9768, 2, 0], [9770, 5, 0], [9839, 2, 7], [9879, 0, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z6QAtG28eXPo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "314e4529-ad2b-4eef-d86d-93ed4a7b4bd7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "false_data_index = np.random.randint(len(index_label_prediction_list))\n",
        "\n",
        "print('len of index_label_prediction_list => ', len(index_label_prediction_list), ', false_data_index => ', false_data_index)\n",
        "\n",
        "mnist_index = index_label_prediction_list[false_data_index][0]\n",
        "label = index_label_prediction_list[false_data_index][1]\n",
        "prediction = index_label_prediction_list[false_data_index][2]\n",
        "\n",
        "title_str = 'index = ' + str(mnist_index) + ' , label = ' + str(label) + ' , prediction = ' + str(prediction)\n",
        "\n",
        "img = test_x_data[mnist_index].reshape(28,28)\n",
        "\n",
        "\n",
        "plt.title(title_str)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of index_label_prediction_list =>  94 , false_data_index =>  46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp2Yzg5JGHrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}