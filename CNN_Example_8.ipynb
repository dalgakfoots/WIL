{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "CNN_Example_8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O-Pv5fJG1KiA"
      },
      "source": [
        "### [예제 8] 3conv_3X3_3X3_3X3_NoPooling_FC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhvBrcge1KiE",
        "outputId": "42b30045-c5dd-4ad4-fa7e-6cece1bba53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# colab 에서 tensorflow 1.x 실행\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bt2ciGRak9-I",
        "outputId": "e6405a4e-85d7-4a2b-9be6-b9a698623281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
        "\n",
        "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
        "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
        "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
        "\n",
        "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
        "\n",
        "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
        "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
        "\n",
        "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            " 55000 10000 5000\n",
            "\n",
            "train image shape =  (55000, 784)\n",
            "train label shape =  (55000, 10)\n",
            "test image shape =  (10000, 784)\n",
            "test label shape =  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1Doo13ik9-O",
        "colab": {}
      },
      "source": [
        "# Hyper-Parameter\n",
        "learning_rate = 0.001  # 학습율\n",
        "epochs = 50            # 반복횟수\n",
        "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dbHu2Xnek9-S",
        "colab": {}
      },
      "source": [
        "# 입력과 정답을 위한 플레이스홀더 정의\n",
        "X = tf.placeholder(tf.float32, [None, 784])  \n",
        "\n",
        "T = tf.placeholder(tf.float32, [None, 10])  \n",
        "\n",
        "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
        "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28 X 28 X 1 (black/white)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-YcxLO1k9-V",
        "colab": {}
      },
      "source": [
        "# 1번째 컨볼루션 층\n",
        "\n",
        "F2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  \n",
        "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
        "\n",
        "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
        "C2 = tf.nn.conv2d(A1, F2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z2 = tf.nn.relu(C2+b2)\n",
        "\n",
        "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
        "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wWx5urPxk9-Y",
        "colab": {}
      },
      "source": [
        "# 2번째 컨볼루션 층\n",
        "F3 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))  \n",
        "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
        "\n",
        "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
        "C3 = tf.nn.conv2d(A2, F3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z3 = tf.nn.relu(C3+b3)\n",
        "\n",
        "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
        "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gNxBw9Fbk9-b",
        "colab": {}
      },
      "source": [
        "# 3번째 컨볼루션 층\n",
        "F4 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))  \n",
        "b4 = tf.Variable(tf.constant(0.1, shape=[128]))   \n",
        "\n",
        "# 3번째 컨볼루션 연산을 통해 7 X 7 X 64 => 7 X 7 X 128\n",
        "C4 = tf.nn.conv2d(A3, F4, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "A4 = Z4 = tf.nn.relu(C4+b4)\n",
        "\n",
        "# pooling 없음 \n",
        "#A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HoKyURwwk9-d",
        "colab": {}
      },
      "source": [
        "# 4X4 크기를 가진 128개의 activation map을 flatten 시킴\n",
        "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*7*7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vRk70vhk9-g",
        "colab": {}
      },
      "source": [
        "# 출력층\n",
        "W5 = tf.Variable(tf.random_normal([128*7*7, 10], stddev=0.01))\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "# 출력층 선형회귀  값 Z5, 즉 softmax 에 들어가는 입력 값\n",
        "Z5 = logits = tf.matmul(A4_flat, W5) + b5    # 선형회귀 값 Z5\n",
        "\n",
        "y = A5 = tf.nn.softmax(Z5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "prsLY0U6k9-j",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5, labels=T) )\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "stkXP6Evk9-l",
        "colab": {}
      },
      "source": [
        "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
        "predicted_val = tf.equal( tf.argmax(A5, 1), tf.argmax(T, 1) )\n",
        "\n",
        "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
        "\n",
        "# index list 출력\n",
        "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
        "\n",
        "# 예측값 처리\n",
        "predicted_list = tf.argmax(A5, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s9t7mdaWk9-m",
        "outputId": "dda4c36e-9989-477f-ee92-9acdd80010f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "index_label_prediction_list = []\n",
        "\n",
        "with  tf.Session()  as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    for i in range(epochs):    # 30 번 반복수행\n",
        "        \n",
        "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
        "\n",
        "        for step in range(total_batch):\n",
        "            \n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
        "        \n",
        "            if step % 100 == 0:\n",
        "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
        "    \n",
        "    end_time = datetime.now() \n",
        "    \n",
        "    print(\"\\nelapsed time = \", end_time - start_time) \n",
        "    \n",
        "    # Accuracy 확인\n",
        "    test_x_data = mnist.test.images    # 10000 X 784\n",
        "    test_t_data = mnist.test.labels    # 10000 X 10\n",
        "    \n",
        "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
        "    \n",
        "    print(\"\\nAccuracy = \", accuracy_val)\n",
        "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
        "    print(\"index_label.shape = \", index_label.shape)\n",
        "    \n",
        "    index_label_list = list(index_label)\n",
        "    print(\"length of index_label_list = \", len(index_label_list))\n",
        "    print(\"false label count = \", index_label_list.count([0]))\n",
        "        \n",
        "    # numpy type 으로 디버그\n",
        "    temp_list = [] \n",
        "    \n",
        "    for index in range(len(index_label)):\n",
        "        \n",
        "        if index_label[index] == 0:\n",
        "            \n",
        "            temp_list.append(index)\n",
        "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
        "            temp_list.append(predicted_list_val[index])\n",
        "            \n",
        "            index_label_prediction_list.append(temp_list)\n",
        "            \n",
        "            temp_list = []\n",
        "            \n",
        "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs =  0 , step =  0 , loss_val =  2.8734422\n",
            "epochs =  0 , step =  100 , loss_val =  0.783646\n",
            "epochs =  0 , step =  200 , loss_val =  0.33117676\n",
            "epochs =  0 , step =  300 , loss_val =  0.20388807\n",
            "epochs =  0 , step =  400 , loss_val =  0.12880492\n",
            "epochs =  0 , step =  500 , loss_val =  0.06956625\n",
            "epochs =  1 , step =  0 , loss_val =  0.09348085\n",
            "epochs =  1 , step =  100 , loss_val =  0.038166862\n",
            "epochs =  1 , step =  200 , loss_val =  0.035195492\n",
            "epochs =  1 , step =  300 , loss_val =  0.08400944\n",
            "epochs =  1 , step =  400 , loss_val =  0.03467237\n",
            "epochs =  1 , step =  500 , loss_val =  0.079028726\n",
            "epochs =  2 , step =  0 , loss_val =  0.07236454\n",
            "epochs =  2 , step =  100 , loss_val =  0.05964979\n",
            "epochs =  2 , step =  200 , loss_val =  0.020009954\n",
            "epochs =  2 , step =  300 , loss_val =  0.018287838\n",
            "epochs =  2 , step =  400 , loss_val =  0.028859796\n",
            "epochs =  2 , step =  500 , loss_val =  0.055996712\n",
            "epochs =  3 , step =  0 , loss_val =  0.069246456\n",
            "epochs =  3 , step =  100 , loss_val =  0.0068033673\n",
            "epochs =  3 , step =  200 , loss_val =  0.009780394\n",
            "epochs =  3 , step =  300 , loss_val =  0.022482168\n",
            "epochs =  3 , step =  400 , loss_val =  0.009027401\n",
            "epochs =  3 , step =  500 , loss_val =  0.030527225\n",
            "epochs =  4 , step =  0 , loss_val =  0.006646497\n",
            "epochs =  4 , step =  100 , loss_val =  0.019929083\n",
            "epochs =  4 , step =  200 , loss_val =  0.032090202\n",
            "epochs =  4 , step =  300 , loss_val =  0.0155935725\n",
            "epochs =  4 , step =  400 , loss_val =  0.010975398\n",
            "epochs =  4 , step =  500 , loss_val =  0.046531964\n",
            "epochs =  5 , step =  0 , loss_val =  0.015195137\n",
            "epochs =  5 , step =  100 , loss_val =  0.010267126\n",
            "epochs =  5 , step =  200 , loss_val =  0.0041388236\n",
            "epochs =  5 , step =  300 , loss_val =  0.02209366\n",
            "epochs =  5 , step =  400 , loss_val =  0.0036418866\n",
            "epochs =  5 , step =  500 , loss_val =  0.035952665\n",
            "epochs =  6 , step =  0 , loss_val =  0.0017380569\n",
            "epochs =  6 , step =  100 , loss_val =  0.004463436\n",
            "epochs =  6 , step =  200 , loss_val =  0.04115195\n",
            "epochs =  6 , step =  300 , loss_val =  0.019561704\n",
            "epochs =  6 , step =  400 , loss_val =  0.013808935\n",
            "epochs =  6 , step =  500 , loss_val =  0.014979195\n",
            "epochs =  7 , step =  0 , loss_val =  0.0016862272\n",
            "epochs =  7 , step =  100 , loss_val =  0.0058475025\n",
            "epochs =  7 , step =  200 , loss_val =  0.0030339519\n",
            "epochs =  7 , step =  300 , loss_val =  8.671496e-05\n",
            "epochs =  7 , step =  400 , loss_val =  0.0012410592\n",
            "epochs =  7 , step =  500 , loss_val =  0.0015087044\n",
            "epochs =  8 , step =  0 , loss_val =  0.0034239443\n",
            "epochs =  8 , step =  100 , loss_val =  0.00086922094\n",
            "epochs =  8 , step =  200 , loss_val =  0.0037092576\n",
            "epochs =  8 , step =  300 , loss_val =  0.00046249584\n",
            "epochs =  8 , step =  400 , loss_val =  0.00061682484\n",
            "epochs =  8 , step =  500 , loss_val =  0.0016773257\n",
            "epochs =  9 , step =  0 , loss_val =  0.0015144821\n",
            "epochs =  9 , step =  100 , loss_val =  0.003506689\n",
            "epochs =  9 , step =  200 , loss_val =  0.009665578\n",
            "epochs =  9 , step =  300 , loss_val =  0.0010355368\n",
            "epochs =  9 , step =  400 , loss_val =  0.01836751\n",
            "epochs =  9 , step =  500 , loss_val =  0.0009144267\n",
            "epochs =  10 , step =  0 , loss_val =  0.00059410086\n",
            "epochs =  10 , step =  100 , loss_val =  0.005086906\n",
            "epochs =  10 , step =  200 , loss_val =  0.023554638\n",
            "epochs =  10 , step =  300 , loss_val =  0.0019370259\n",
            "epochs =  10 , step =  400 , loss_val =  0.000109825014\n",
            "epochs =  10 , step =  500 , loss_val =  0.00952814\n",
            "epochs =  11 , step =  0 , loss_val =  0.006149267\n",
            "epochs =  11 , step =  100 , loss_val =  8.052653e-05\n",
            "epochs =  11 , step =  200 , loss_val =  3.348139e-05\n",
            "epochs =  11 , step =  300 , loss_val =  8.6622706e-05\n",
            "epochs =  11 , step =  400 , loss_val =  0.005429837\n",
            "epochs =  11 , step =  500 , loss_val =  0.0016497778\n",
            "epochs =  12 , step =  0 , loss_val =  0.00083112693\n",
            "epochs =  12 , step =  100 , loss_val =  0.009178504\n",
            "epochs =  12 , step =  200 , loss_val =  0.0016787018\n",
            "epochs =  12 , step =  300 , loss_val =  0.016573057\n",
            "epochs =  12 , step =  400 , loss_val =  0.0017764029\n",
            "epochs =  12 , step =  500 , loss_val =  0.0014480877\n",
            "epochs =  13 , step =  0 , loss_val =  0.00048000593\n",
            "epochs =  13 , step =  100 , loss_val =  0.0019336599\n",
            "epochs =  13 , step =  200 , loss_val =  0.007434758\n",
            "epochs =  13 , step =  300 , loss_val =  0.00076303014\n",
            "epochs =  13 , step =  400 , loss_val =  0.0021977369\n",
            "epochs =  13 , step =  500 , loss_val =  8.572433e-05\n",
            "epochs =  14 , step =  0 , loss_val =  0.00016019546\n",
            "epochs =  14 , step =  100 , loss_val =  0.0010368355\n",
            "epochs =  14 , step =  200 , loss_val =  0.00052618585\n",
            "epochs =  14 , step =  300 , loss_val =  0.00014318229\n",
            "epochs =  14 , step =  400 , loss_val =  0.0006223336\n",
            "epochs =  14 , step =  500 , loss_val =  8.162829e-06\n",
            "epochs =  15 , step =  0 , loss_val =  0.0013423505\n",
            "epochs =  15 , step =  100 , loss_val =  0.0005524901\n",
            "epochs =  15 , step =  200 , loss_val =  0.0013954003\n",
            "epochs =  15 , step =  300 , loss_val =  0.00012372505\n",
            "epochs =  15 , step =  400 , loss_val =  0.021409385\n",
            "epochs =  15 , step =  500 , loss_val =  0.0022445824\n",
            "epochs =  16 , step =  0 , loss_val =  0.0006959113\n",
            "epochs =  16 , step =  100 , loss_val =  0.007195501\n",
            "epochs =  16 , step =  200 , loss_val =  2.7161517e-05\n",
            "epochs =  16 , step =  300 , loss_val =  0.00017878195\n",
            "epochs =  16 , step =  400 , loss_val =  0.0029423893\n",
            "epochs =  16 , step =  500 , loss_val =  0.0031613857\n",
            "epochs =  17 , step =  0 , loss_val =  0.0017797363\n",
            "epochs =  17 , step =  100 , loss_val =  0.00053311174\n",
            "epochs =  17 , step =  200 , loss_val =  0.0007560564\n",
            "epochs =  17 , step =  300 , loss_val =  0.0013699532\n",
            "epochs =  17 , step =  400 , loss_val =  0.0015211913\n",
            "epochs =  17 , step =  500 , loss_val =  6.6831664e-05\n",
            "epochs =  18 , step =  0 , loss_val =  9.975416e-06\n",
            "epochs =  18 , step =  100 , loss_val =  0.00012187386\n",
            "epochs =  18 , step =  200 , loss_val =  0.03177858\n",
            "epochs =  18 , step =  300 , loss_val =  4.874605e-05\n",
            "epochs =  18 , step =  400 , loss_val =  0.00097570533\n",
            "epochs =  18 , step =  500 , loss_val =  0.0007433878\n",
            "epochs =  19 , step =  0 , loss_val =  3.6635018e-05\n",
            "epochs =  19 , step =  100 , loss_val =  0.00036253902\n",
            "epochs =  19 , step =  200 , loss_val =  6.2082086e-06\n",
            "epochs =  19 , step =  300 , loss_val =  0.00025005316\n",
            "epochs =  19 , step =  400 , loss_val =  0.0003116844\n",
            "epochs =  19 , step =  500 , loss_val =  0.00013680897\n",
            "epochs =  20 , step =  0 , loss_val =  6.294984e-05\n",
            "epochs =  20 , step =  100 , loss_val =  0.02799989\n",
            "epochs =  20 , step =  200 , loss_val =  0.0030242747\n",
            "epochs =  20 , step =  300 , loss_val =  0.003425065\n",
            "epochs =  20 , step =  400 , loss_val =  0.00085705327\n",
            "epochs =  20 , step =  500 , loss_val =  2.0669866e-06\n",
            "epochs =  21 , step =  0 , loss_val =  1.495536e-05\n",
            "epochs =  21 , step =  100 , loss_val =  0.028998079\n",
            "epochs =  21 , step =  200 , loss_val =  0.0035845945\n",
            "epochs =  21 , step =  300 , loss_val =  3.570639e-05\n",
            "epochs =  21 , step =  400 , loss_val =  0.0022968887\n",
            "epochs =  21 , step =  500 , loss_val =  0.0033036927\n",
            "epochs =  22 , step =  0 , loss_val =  9.844757e-05\n",
            "epochs =  22 , step =  100 , loss_val =  5.0260132e-06\n",
            "epochs =  22 , step =  200 , loss_val =  0.0005619692\n",
            "epochs =  22 , step =  300 , loss_val =  0.0035051373\n",
            "epochs =  22 , step =  400 , loss_val =  0.00244149\n",
            "epochs =  22 , step =  500 , loss_val =  0.00025639648\n",
            "epochs =  23 , step =  0 , loss_val =  0.00012404393\n",
            "epochs =  23 , step =  100 , loss_val =  0.00067465636\n",
            "epochs =  23 , step =  200 , loss_val =  3.1260777e-05\n",
            "epochs =  23 , step =  300 , loss_val =  0.014972976\n",
            "epochs =  23 , step =  400 , loss_val =  0.00095839583\n",
            "epochs =  23 , step =  500 , loss_val =  0.00020793537\n",
            "epochs =  24 , step =  0 , loss_val =  2.436535e-06\n",
            "epochs =  24 , step =  100 , loss_val =  9.405147e-06\n",
            "epochs =  24 , step =  200 , loss_val =  0.0056269024\n",
            "epochs =  24 , step =  300 , loss_val =  0.00027959433\n",
            "epochs =  24 , step =  400 , loss_val =  3.2482785e-05\n",
            "epochs =  24 , step =  500 , loss_val =  0.0011522492\n",
            "epochs =  25 , step =  0 , loss_val =  7.418603e-05\n",
            "epochs =  25 , step =  100 , loss_val =  0.00011110412\n",
            "epochs =  25 , step =  200 , loss_val =  0.00011293238\n",
            "epochs =  25 , step =  300 , loss_val =  0.000282145\n",
            "epochs =  25 , step =  400 , loss_val =  2.1944713e-06\n",
            "epochs =  25 , step =  500 , loss_val =  0.0002620227\n",
            "epochs =  26 , step =  0 , loss_val =  9.13092e-06\n",
            "epochs =  26 , step =  100 , loss_val =  3.7433747e-05\n",
            "epochs =  26 , step =  200 , loss_val =  5.0156177e-06\n",
            "epochs =  26 , step =  300 , loss_val =  1.870057e-05\n",
            "epochs =  26 , step =  400 , loss_val =  0.0019519922\n",
            "epochs =  26 , step =  500 , loss_val =  0.00035907992\n",
            "epochs =  27 , step =  0 , loss_val =  1.766171e-05\n",
            "epochs =  27 , step =  100 , loss_val =  1.709579e-05\n",
            "epochs =  27 , step =  200 , loss_val =  9.680221e-05\n",
            "epochs =  27 , step =  300 , loss_val =  0.0001204986\n",
            "epochs =  27 , step =  400 , loss_val =  4.684872e-07\n",
            "epochs =  27 , step =  500 , loss_val =  4.684376e-05\n",
            "epochs =  28 , step =  0 , loss_val =  1.358981e-07\n",
            "epochs =  28 , step =  100 , loss_val =  0.0013504243\n",
            "epochs =  28 , step =  200 , loss_val =  6.604544e-06\n",
            "epochs =  28 , step =  300 , loss_val =  0.00043290414\n",
            "epochs =  28 , step =  400 , loss_val =  0.0026619574\n",
            "epochs =  28 , step =  500 , loss_val =  1.6593563e-05\n",
            "epochs =  29 , step =  0 , loss_val =  7.3508395e-06\n",
            "epochs =  29 , step =  100 , loss_val =  0.00027786483\n",
            "epochs =  29 , step =  200 , loss_val =  0.003918448\n",
            "epochs =  29 , step =  300 , loss_val =  0.0006448964\n",
            "epochs =  29 , step =  400 , loss_val =  3.564325e-07\n",
            "epochs =  29 , step =  500 , loss_val =  3.811935e-05\n",
            "epochs =  30 , step =  0 , loss_val =  0.00011243178\n",
            "epochs =  30 , step =  100 , loss_val =  4.939431e-05\n",
            "epochs =  30 , step =  200 , loss_val =  2.5211243e-06\n",
            "epochs =  30 , step =  300 , loss_val =  0.0001475667\n",
            "epochs =  30 , step =  400 , loss_val =  0.05709834\n",
            "epochs =  30 , step =  500 , loss_val =  0.00017710237\n",
            "epochs =  31 , step =  0 , loss_val =  1.5276119e-05\n",
            "epochs =  31 , step =  100 , loss_val =  0.0003420169\n",
            "epochs =  31 , step =  200 , loss_val =  0.0006526548\n",
            "epochs =  31 , step =  300 , loss_val =  2.1455948e-05\n",
            "epochs =  31 , step =  400 , loss_val =  0.00040819292\n",
            "epochs =  31 , step =  500 , loss_val =  9.59563e-05\n",
            "epochs =  32 , step =  0 , loss_val =  3.9297593e-06\n",
            "epochs =  32 , step =  100 , loss_val =  1.1473745e-05\n",
            "epochs =  32 , step =  200 , loss_val =  5.9604552e-08\n",
            "epochs =  32 , step =  300 , loss_val =  4.3391577e-07\n",
            "epochs =  32 , step =  400 , loss_val =  0.0024534755\n",
            "epochs =  32 , step =  500 , loss_val =  2.3113944e-06\n",
            "epochs =  33 , step =  0 , loss_val =  7.876468e-06\n",
            "epochs =  33 , step =  100 , loss_val =  1.7642917e-07\n",
            "epochs =  33 , step =  200 , loss_val =  0.03166977\n",
            "epochs =  33 , step =  300 , loss_val =  1.0051594e-05\n",
            "epochs =  33 , step =  400 , loss_val =  1.2777788e-05\n",
            "epochs =  33 , step =  500 , loss_val =  3.7431448e-07\n",
            "epochs =  34 , step =  0 , loss_val =  3.1575369e-06\n",
            "epochs =  34 , step =  100 , loss_val =  0.0018585845\n",
            "epochs =  34 , step =  200 , loss_val =  1.7262953e-05\n",
            "epochs =  34 , step =  300 , loss_val =  3.6368392e-06\n",
            "epochs =  34 , step =  400 , loss_val =  2.0513104e-05\n",
            "epochs =  34 , step =  500 , loss_val =  2.0427951e-05\n",
            "epochs =  35 , step =  0 , loss_val =  1.4948423e-06\n",
            "epochs =  35 , step =  100 , loss_val =  5.5206356e-06\n",
            "epochs =  35 , step =  200 , loss_val =  0.0033841897\n",
            "epochs =  35 , step =  300 , loss_val =  0.0002900164\n",
            "epochs =  35 , step =  400 , loss_val =  5.325669e-06\n",
            "epochs =  35 , step =  500 , loss_val =  3.7073625e-07\n",
            "epochs =  36 , step =  0 , loss_val =  0.0003357152\n",
            "epochs =  36 , step =  100 , loss_val =  4.5723514e-06\n",
            "epochs =  36 , step =  200 , loss_val =  2.749764e-05\n",
            "epochs =  36 , step =  300 , loss_val =  0.00082204794\n",
            "epochs =  36 , step =  400 , loss_val =  4.851703e-07\n",
            "epochs =  36 , step =  500 , loss_val =  1.0132761e-07\n",
            "epochs =  37 , step =  0 , loss_val =  0.0001672219\n",
            "epochs =  37 , step =  100 , loss_val =  8.940674e-08\n",
            "epochs =  37 , step =  200 , loss_val =  5.64294e-06\n",
            "epochs =  37 , step =  300 , loss_val =  4.565885e-06\n",
            "epochs =  37 , step =  400 , loss_val =  1.2635786e-06\n",
            "epochs =  37 , step =  500 , loss_val =  1.0027088e-05\n",
            "epochs =  38 , step =  0 , loss_val =  4.204893e-05\n",
            "epochs =  38 , step =  100 , loss_val =  1.5567937e-06\n",
            "epochs =  38 , step =  200 , loss_val =  7.1525563e-09\n",
            "epochs =  38 , step =  300 , loss_val =  4.33977e-06\n",
            "epochs =  38 , step =  400 , loss_val =  1.8297076e-06\n",
            "epochs =  38 , step =  500 , loss_val =  1.0454155e-06\n",
            "epochs =  39 , step =  0 , loss_val =  2.9682943e-07\n",
            "epochs =  39 , step =  100 , loss_val =  4.222926e-06\n",
            "epochs =  39 , step =  200 , loss_val =  7.4120117e-06\n",
            "epochs =  39 , step =  300 , loss_val =  7.6100023e-06\n",
            "epochs =  39 , step =  400 , loss_val =  5.856125e-06\n",
            "epochs =  39 , step =  500 , loss_val =  1.4304517e-06\n",
            "epochs =  40 , step =  0 , loss_val =  1.6808384e-07\n",
            "epochs =  40 , step =  100 , loss_val =  2.3960823e-07\n",
            "epochs =  40 , step =  200 , loss_val =  1.8596488e-07\n",
            "epochs =  40 , step =  300 , loss_val =  1.4305113e-08\n",
            "epochs =  40 , step =  400 , loss_val =  1.0001321e-06\n",
            "epochs =  40 , step =  500 , loss_val =  3.357578e-06\n",
            "epochs =  41 , step =  0 , loss_val =  7.748587e-08\n",
            "epochs =  41 , step =  100 , loss_val =  6.8546437e-06\n",
            "epochs =  41 , step =  200 , loss_val =  9.5125034e-07\n",
            "epochs =  41 , step =  300 , loss_val =  1.5258742e-07\n",
            "epochs =  41 , step =  400 , loss_val =  4.7683606e-08\n",
            "epochs =  41 , step =  500 , loss_val =  1.6331573e-07\n",
            "epochs =  42 , step =  0 , loss_val =  1.9525346e-06\n",
            "epochs =  42 , step =  100 , loss_val =  8.296775e-07\n",
            "epochs =  42 , step =  200 , loss_val =  1.02519735e-07\n",
            "epochs =  42 , step =  300 , loss_val =  6.461072e-07\n",
            "epochs =  42 , step =  400 , loss_val =  6.55649e-08\n",
            "epochs =  42 , step =  500 , loss_val =  1.7404463e-07\n",
            "epochs =  43 , step =  0 , loss_val =  1.283809e-06\n",
            "epochs =  43 , step =  100 , loss_val =  4.3561595e-06\n",
            "epochs =  43 , step =  200 , loss_val =  1.4078099e-06\n",
            "epochs =  43 , step =  300 , loss_val =  3.337856e-08\n",
            "epochs =  43 , step =  400 , loss_val =  3.2634887e-06\n",
            "epochs =  43 , step =  500 , loss_val =  3.695486e-08\n",
            "epochs =  44 , step =  0 , loss_val =  3.123243e-07\n",
            "epochs =  44 , step =  100 , loss_val =  7.8677886e-08\n",
            "epochs =  44 , step =  200 , loss_val =  7.9151874e-07\n",
            "epochs =  44 , step =  300 , loss_val =  2.2649749e-08\n",
            "epochs =  44 , step =  400 , loss_val =  2.6702605e-07\n",
            "epochs =  44 , step =  500 , loss_val =  1.5497204e-08\n",
            "epochs =  45 , step =  0 , loss_val =  1.3935106e-06\n",
            "epochs =  45 , step =  100 , loss_val =  4.5060705e-07\n",
            "epochs =  45 , step =  200 , loss_val =  3.232575e-06\n",
            "epochs =  45 , step =  300 , loss_val =  2.5152917e-07\n",
            "epochs =  45 , step =  400 , loss_val =  3.3638598e-06\n",
            "epochs =  45 , step =  500 , loss_val =  3.9219512e-07\n",
            "epochs =  46 , step =  0 , loss_val =  3.576238e-07\n",
            "epochs =  46 , step =  100 , loss_val =  1.3113017e-08\n",
            "epochs =  46 , step =  200 , loss_val =  4.768371e-09\n",
            "epochs =  46 , step =  300 , loss_val =  2.1338342e-07\n",
            "epochs =  46 , step =  400 , loss_val =  2.2530304e-07\n",
            "epochs =  46 , step =  500 , loss_val =  3.230541e-07\n",
            "epochs =  47 , step =  0 , loss_val =  1.1598426e-06\n",
            "epochs =  47 , step =  100 , loss_val =  4.7683715e-09\n",
            "epochs =  47 , step =  200 , loss_val =  9.655918e-08\n",
            "epochs =  47 , step =  300 , loss_val =  7.1525484e-08\n",
            "epochs =  47 , step =  400 , loss_val =  1.7188602e-06\n",
            "epochs =  47 , step =  500 , loss_val =  0.0\n",
            "epochs =  48 , step =  0 , loss_val =  3.445091e-07\n",
            "epochs =  48 , step =  100 , loss_val =  4.386816e-07\n",
            "epochs =  48 , step =  200 , loss_val =  1.9311796e-07\n",
            "epochs =  48 , step =  300 , loss_val =  3.5643072e-07\n",
            "epochs =  48 , step =  400 , loss_val =  7.164329e-07\n",
            "epochs =  48 , step =  500 , loss_val =  1.811967e-07\n",
            "epochs =  49 , step =  0 , loss_val =  3.7669426e-07\n",
            "epochs =  49 , step =  100 , loss_val =  8.4638295e-08\n",
            "epochs =  49 , step =  200 , loss_val =  1.0728788e-07\n",
            "epochs =  49 , step =  300 , loss_val =  2.0384712e-07\n",
            "epochs =  49 , step =  400 , loss_val =  8.1536854e-07\n",
            "epochs =  49 , step =  500 , loss_val =  1.430511e-08\n",
            "\n",
            "elapsed time =  0:02:24.343455\n",
            "\n",
            "Accuracy =  0.9929\n",
            "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
            "index_label.shape =  (10000,)\n",
            "length of index_label_list =  10000\n",
            "false label count =  71\n",
            "\n",
            "length of index_label_false_list 71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48THz29lk9-o",
        "outputId": "c1449197-2211-4177-acf7-9cb4753f5649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# index_label_prediction_list\n",
        "print(index_label_prediction_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[340, 5, 3], [445, 6, 0], [582, 8, 2], [659, 2, 1], [674, 5, 3], [938, 3, 5], [947, 8, 9], [1014, 6, 5], [1112, 4, 6], [1224, 2, 4], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1319, 8, 0], [1393, 5, 3], [1414, 9, 4], [1709, 9, 5], [1878, 8, 3], [1901, 9, 4], [2035, 5, 3], [2070, 7, 9], [2098, 2, 0], [2118, 6, 0], [2129, 9, 2], [2130, 4, 9], [2135, 6, 1], [2293, 9, 4], [2314, 7, 4], [2597, 5, 3], [2654, 6, 1], [2678, 4, 9], [2896, 8, 0], [2927, 3, 2], [2939, 9, 5], [2953, 3, 5], [2959, 2, 3], [3073, 1, 2], [3422, 6, 0], [3520, 6, 4], [3558, 5, 0], [3808, 7, 8], [4007, 7, 9], [4078, 9, 8], [4176, 2, 7], [4201, 1, 7], [4284, 9, 5], [4360, 5, 3], [4369, 9, 4], [4382, 4, 9], [4639, 8, 9], [4740, 3, 5], [4783, 4, 9], [4814, 6, 0], [4823, 9, 4], [4860, 4, 9], [5457, 1, 4], [5654, 7, 2], [5936, 4, 9], [5937, 5, 3], [5955, 3, 8], [6571, 9, 7], [6576, 7, 1], [6597, 0, 7], [6651, 0, 8], [7216, 0, 6], [8094, 2, 8], [8246, 3, 5], [9015, 7, 2], [9505, 7, 2], [9729, 5, 6], [9792, 4, 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZjMMkZkdk9-p",
        "outputId": "6996b567-13d9-484e-fd0f-f7a2619bd627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "false_data_index = np.random.randint(len(index_label_prediction_list))\n",
        "\n",
        "print('len of index_label_prediction_list => ', len(index_label_prediction_list), ', false_data_index => ', false_data_index)\n",
        "\n",
        "mnist_index = index_label_prediction_list[false_data_index][0]\n",
        "label = index_label_prediction_list[false_data_index][1]\n",
        "prediction = index_label_prediction_list[false_data_index][2]\n",
        "\n",
        "title_str = 'index = ' + str(mnist_index) + ' , label = ' + str(label) + ' , prediction = ' + str(prediction)\n",
        "\n",
        "img = test_x_data[mnist_index].reshape(28,28)\n",
        "\n",
        "\n",
        "plt.title(title_str)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of index_label_prediction_list =>  71 , false_data_index =>  6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3GVrLMouk9-r",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}